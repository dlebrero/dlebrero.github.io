<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]--><!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]--><!--[if IE 9 ]><html class="no-js ie ie9" lang="en"> <![endif]--><!--[if (gte IE 9)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
   <meta charset="utf-8" />
	<title>Proof of concept using KafkaStreams and KTables - implementation notes, gotchas and Docker Compose example</title>
	<meta content="Implementation details from a proof of concept using Kafka Streams and KTables using Clojure and Docker" name="description" /><meta content="Kafka Streams KTable KStream Clojure Docker example" name="keywords" /><meta content="Daniel Lebrero Berna" name="author" /><meta content="Proof of concept using KafkaStreams and KTables - implementation notes, gotchas and Docker Compose example" property="og:title" /><meta content="Implementation details from a proof of concept using Kafka Streams and KTables using Clojure and Docker" property="og:description" /><meta content="http://danlebrero.com/2017/01/06/proof-of-concept-using-kafkastreams-and-ktables-implementation-notes-gotchas-and-docker-compose/" property="og:url" /><meta content="Proof of concept using KafkaStreams and KTables - implementation notes, gotchas and Docker Compose example" name="twitter:title" /><meta content="Implementation details from a proof of concept using Kafka Streams and KTables using Clojure and Docker" name="twitter:description" /><meta content="summary_large_image" name="twitter:card" /><meta content="http://danlebrero.com/images/kafka-streams-poc-kstreams-solution.jpg" name="twitter:image" /><meta content="http://danlebrero.com/images/kafka-streams-poc-kstreams-solution.jpg" property="og:image" />
	<meta name="twitter:site" content="@danlebrero" />
	<meta name="twitter:creator" content="@danlebrero" />

	<link rel="alternate" type="application/rss+xml" title="Daniel Lebrero Berna Blog" href="/feed.rss" />
	<!-- Mobile Specific Metas
    ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="/css/base.css" />
	<link rel="stylesheet" href="/css/main.css" />
   <link rel="stylesheet" href="/css/media-queries.css" />
   <link rel="stylesheet" href="/css/tomorrow-night.min.css" />
   <link rel="stylesheet" href="/css/shariff.min.css" />

   <!-- Script
   =================================================== -->
	<script src="/js/modernizr.js"></script>

   <!-- Favicons
	=================================================== -->
	<link rel="shortcut icon" href="/favicon.ico" />

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87361578-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>

   <div id="preloader">
	   <div id="status">
         <img src="/images/loader.gif" height="60" width="60" alt="" />
         <div class="loader">Loading...</div>
      </div>
   </div>

   <!-- Header
   =================================================== -->
   <header id="main-header">

   	<div class="row header-inner">

	      <!--div class="logo">
	         <a class="smoothscroll" href="#hero">Puremedia.</a>
	      </- -div-->

	      <nav id="nav-wrap">         
	         
	         <a class="mobile-btn" href="#nav-wrap" title="Show navigation">
	         	<span class="menu-text">Show Menu</span>
	         	<span class="menu-icon"></span>
	         </a>
         	<a class="mobile-btn" href="#" title="Hide navigation">
         		<span class="menu-text">Hide Menu</span>
         		<span class="menu-icon"></span>
         	</a>         

	         <ul id="nav" class="nav">
	            <li class="current"><a href="/">Home.</a></li>
				<!--<li id="menu-work"><a class="smoothscroll" href="/portfolio.html">Works.</a></li>-->
	            <li id="menu-archives"><a href="/archives/">Archives.</a></li>
	         </ul>

	      </nav> <!-- /nav-wrap -->	      

	   </div> <!-- /header-inner -->

   </header>


   <!-- Page Title
   ================================================== -->
   <section id="page-title">

		<div class="row">

			<div class="twelve columns">

				<p id="the-title"><a href="/">@DanLebrero<span>.</span></a></p>
				<p>software, simply</p>

			</div>

		</div> <!-- /row -->

   </section> <!-- /page-title -->


   <!-- Content
   ================================================== -->
   <section id="content">

   	<div class="row">

	   	<div id="main" class="tab-whole nine columns">

	         <article class="entry">

					<header class="entry-header">

						<h1 class="entry-title">Proof of concept using KafkaStreams and KTables - implementation notes, gotchas and Docker Compose example</h1>

						<div class="entry-meta">
							<ul>
								<li id="entry-date">Fri, 6 Jan 2017</li>
							</ul>
						</div>

					</header>

				 <p class="lead" id="entry-summary">Implementation details from a proof of concept using Kafka Streams and KTables using Clojure and Docker</p>

				 <div class="entry-content-media">
						<div class="post-thumb">
							<img src="/images/kafka-streams-poc-kstreams-solution.jpg" />
						</div>
					</div>

					<div class="entry-content"><p>This blog contains the implementation notes from the proof of concept explained in the <a href="/2017/01/05/proof-of-concept-using-kafkastreams-and-ktables/#content">previous post</a>.</p><p>As a reminder, we want to build a new microservice whose job is to:</p>
<blockquote><p>Send a weekly email to client’s holding trading positions in a US stock.</p>
</blockquote><p>We will use <a href="https://www.confluent.io/product/kafka-streams/">Kafka Streams</a> and more specifically <a href="http://docs.confluent.io/3.1.1/streams/concepts.html#ktable-changelog-stream">KTables</a> to build it.</p><p>All the code can be found <a href="https://github.com/dlebrero/kafka-streams-and-ktable-example">here</a>, including a Docker Compose file that will run Kafka, Zookeeper plus three instances of this service, so you can play around with it. The details of how to build and run it are in the repository.</p><h2>The plan</h2><p>The order booking system is keeping a Kafka compacted topic updated with any changes in the open positions for each client. The Kafka’s key used is the position’s id.</p><p>This is perfect example of a KTable, which conceptually looks like:</p>
<table>
  <thead>
    <tr>
      <th>PositionId (Key) </th>
      <th align="center">Client </th>
      <th align="right">Ticker </th>
      <th align="right">Amount</th>
      <th align="right">Exchange</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1 </td>
      <td align="center">client1 </td>
      <td align="right">AAPL </td>
      <td align="right">100 </td>
      <td align="right">NASDAQ </td>
    </tr>
    <tr>
      <td>2 </td>
      <td align="center">client1 </td>
      <td align="right">VOD </td>
      <td align="right">5 </td>
      <td align="right">LON </td>
    </tr>
    <tr>
      <td>3 </td>
      <td align="center">client1 </td>
      <td align="right">FB </td>
      <td align="right">33 </td>
      <td align="right">NASDAQ </td>
    </tr>
    <tr>
      <td>4 </td>
      <td align="center">client2 </td>
      <td align="right">AAPL </td>
      <td align="right">25 </td>
      <td align="right">NASDAQ </td>
    </tr>
    <tr>
      <td>5 </td>
      <td align="center">client3 </td>
      <td align="right">VOD </td>
      <td align="right">33 </td>
      <td align="right">LON </td>
    </tr>
  </tbody>
</table><p>We want to transform this KTable into another one that just contains the clients that we want to email, without any duplicates. Something like:</p>
<table>
  <thead>
    <tr>
      <th>Client (Key) </th>
      <th>value </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>client1 </td>
      <td>????? </td>
    </tr>
    <tr>
      <td>client2 </td>
      <td>????? </td>
    </tr>
  </tbody>
</table><p>But what are the values on that table? Well, it has to be the list of US positions for that client so that we keep track of how many the client has and we remove the client from the KTable when he has none open.</p><p>So the KTable that we are looking for is:</p>
<table>
  <thead>
    <tr>
      <th>Client (Key) </th>
      <th>positions </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>client1 </td>
      <td>#{1, 3} </td>
    </tr>
    <tr>
      <td>client2 </td>
      <td>#{4} </td>
    </tr>
  </tbody>
</table><h2>The code</h2><p>To do this transformation we just need this code:</p>
<pre><code class="clojure">(-&gt;
  (.table builder "share-holders" "share-holder-store")
  (.filter (k/pred [key position]
             (= "NASDAQ" (:exchange position))))
  (.groupBy (k/kv-mapper [key position]
              (KeyValue/pair (:client position)
                             #{(:id position)})))
  (.reduce (k/reducer [value1 value2]
             (set/union value1 value2))
           (k/reducer [value1 value2]
             (let [result (set/difference value1 value2)]
               (when-not (empty? result)
                  result)))
           "us-share-holders"))
</code></pre><p>Notice that to create a KTable we specify an associated store. For me it was not obvious why would we need it, but  we will see latter why it is.</p><p><em>GroupBy</em> will make sure that all the positions for a client end up in the same partition. This is a shuffle operation that will need an additional Kafka topic. Kafka Streams will take care of creating this internal topic without us having to do any work or configuration.</p><p>Note that as part of the <em>GroupBy</em> we are also mapping the position to a set with one element, the position id. This is so  we can next use a <em>Reduce</em> instead of the more complex <em>AggregateByKey</em> function.</p><p>As we are working with an infinite stream, <em>Reduce</em> needs two functions, one when a new position is added and the other when the position is deleted. Note that on the delete function, we return <em>null</em> if it was the last position for the client, so the client is removed from the store.</p><p>Lastly, the results of <em>Reduce</em> are stored in the <em>us-share-holders</em> store. This will require another internal topic for fault tolerance.</p><p>Now that we have the store, we just need to query it to get our list of clients:</p>
<pre><code class="clojure">(with-open [all (.all 
                  (.store kafka-streams 
                          "us-share-holders" 
                          (QueryableStoreTypes/keyValueStore)))]
  (mapv
    (fn [x] (.key x))
    (iterator-seq all)))
</code></pre><p>We just iterate over all the entries in the store, returning just the keys. </p><p>Note that we are just querying the local view of the store, so for each instance of the microservice will see a different set of clients.</p><h2>Gotchas</h2><p>Here is a list of bumps on the road while building this proof of concept.</p><h4>Internal topics not being created</h4><p>We were getting a “Topic not found during partition assignment” exception when starting the KafkaStream:</p>
<pre><code>org.apache.kafka.streams.errors.StreamsException: Topic not found during partition assignment: example-consumer17-us-share-holders-repartition
    at org.apache.kafka.streams.processor.DefaultPartitionGrouper.maxNumPartitions(DefaultPartitionGrouper.java:81)
   	at org.apache.kafka.streams.processor.DefaultPartitionGrouper.partitionGroups(DefaultPartitionGrouper.java:55)
 	at org.apache.kafka.streams.processor.internals.StreamPartitionAssignor.assign(StreamPartitionAssignor.java:370)
</code></pre><p>At first we thought that KafkaStreams required the “auto.create.topics.enable” flag set to true but the <a href="http://docs.confluent.io/3.1.1/streams/developer-guide.html#managing-topics-of-a-kafka-streams-application">documentation</a> strongly discourages it, so it couldn’t be that.</p><p>So we had to dig a little bit more and we found this really helpful WARN in the logs:</p>
<pre><code>WARN ... Topic [...] do not exists but couldn't created as the config 'zookeeper.connect' isn't supplied
</code></pre><p>So should had pay more attention while <a href="http://docs.confluent.io/3.1.1/streams/developer-guide.html#required-configuration-parameters">RTFM!</a></p><h4>30 seconds delay on processing</h4><p>Initially we saw that messages took 30 seconds to be processed, which was surprising as we expected real time processing. </p><p>So after a quick search and <a href="http://docs.confluent.io/3.1.1/streams/developer-guide.html#record-caches-in-the-dsl">RTFM</a>, we learned that KafkaStreams has an internal cache and that no processing happens until that cache is full or the <em>commit.interval.ms</em> time has elapsed, whatever happens first. The size of the cache can be controlled with the <em>cache.max.bytes.buffering</em> setting.</p><p>This cache allows for a better throughput as it enables compaction before processing plus batch writes to Kafka and RocksDB.</p><p>Both parameters can be tuned to match the latency or throughput requirements of your application. Setting <em>cache.max.bytes.buffering</em> to 0 will make KafkaStreams real time again, processing one message at a time.</p><p>All is nicely explained in the <a href="http://docs.confluent.io/3.1.1/streams/developer-guide.html#record-caches-in-the-dsl">documentation</a>.</p><h4>KTable associated store</h4><p>We also did not understood why when creating a KTable we had to specify a store; at the end of the day, we were not interested on the original KTable but on the transformed one. </p><p>All became more clear when we got to implement the <em>reduce</em> function. </p><p>Lets see what happens when we add a new position:</p>
<pre><code class="accesslog">INFO - Producing {:topic share-holders, :key daniel:::AAPL, :value {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}}
INFO - Filtering daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - Grouping daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - [KTABLE-REDUCE-0000000006]: daniel , (#{"daniel:::AAPL"}&lt;-null)
</code></pre><p>Nothing weird so far, but notice that <em>reduce</em> is not called at all; but that makes sense as it is the very first position for this client.</p><p>Let’s now remove that position:</p>
<pre><code class="accesslog">INFO - Producing {:topic share-holders, :key daniel:::AAPL, :value nil}
INFO - Filtering daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - Grouping daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - Removing from #{daniel:::AAPL} the position #{daniel:::AAPL}
INFO - [KTABLE-REDUCE-0000000006]: daniel , (null&lt;-null)
</code></pre><p>That is interesting. <em>filter</em> and <em>grouping</em> are being called with the position that has been closed. </p><p>So that is why the KTable requires a store, to remember what was the last value for a key. If KafkaStreams did not remember what was the last value, we would have a really hard time to implement the removal of the position as the Kafka message that triggers the <em>reduce</em> just has a <em>null</em> payload. That is pretty neat!</p><p>But what happens when we update a position?</p>
<pre><code class="accesslog">INFO - Producing {:topic share-holders, :key daniel:::AAPL, :value {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}}
INFO - Filtering daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - Grouping daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - [KTABLE-REDUCE-0000000006]: daniel , (#{"daniel:::AAPL"}&lt;-null)
INFO - Producing {:topic share-holders, :key daniel:::AAPL, :value {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 1}}
INFO - Filtering daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 1}
INFO - Filtering daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - Grouping daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 1}
INFO - Grouping daniel:::AAPL {:client daniel, :id daniel:::AAPL, :ticker AAPL, :exchange NASDAQ, :amount 99}
INFO - removing #{daniel:::AAPL} #{daniel:::AAPL}
INFO - [KTABLE-REDUCE-0000000006]: daniel , (null&lt;-null)
INFO - [KTABLE-REDUCE-0000000006]: daniel , (#{"daniel:::AAPL"}&lt;-null)
</code></pre><p>So an update is generating two events: one stating that the client has no positions followed immediately by other one adding the position back. That is not so neat! </p><p>But this is because we have set the <em>cache.max.bytes.buffering</em> to 0. With some caching, only the last value would be produced.</p><p>Something to keep in mind!</p></div>

				 


				 <p class="tags">
	  			     	<span>Tagged in </span>:
	  				  	<a href="/tags/Architecture/index.html">Architecture </a><a href="/tags/Clojure/index.html">Clojure </a>
	  			   </p>

				 <div class="shariff" data-lang="en" data-twitter-via="danlebrero" data-services="[&quot;reddit&quot;,&quot;twitter&quot;, &quot;linkedin&quot;,&quot;facebook&quot;,&quot;googleplus&quot;]"></div>

				 <div id="pagenav" class="pagenav group">
		  			   <span class="prev"><a href="/2017/01/05/proof-of-concept-using-kafkastreams-and-ktables/#content" rel="prev">Previous</a></span>
		  				<span class="next"><a href="/2017/03/26/Kerberos-explained-in-pictures/#content" rel="next">Next</a></span>
	  				</div>

				</article> <!-- /entry -->

	   	</div> <!-- /main -->

	      <div class="tab-whole three columns end" id="secondary">

				<aside id="sidebar">

	             <!-- /widget_search -->

	            <div class="widget widget_text">

	               <h5 class="widget-title">About me</h5>
	               <div class="textwidget">
					   <img class="pull-left" style="border-radius: 5a 0%;" src="http://en.gravatar.com/userimage/38792381/b0f54df774ad03c9b8c553be0af3b322.jpeg" />
					   Daniel Lebrero works as a technical architect at IG on the Big Data team.
					   With more than 15 years of Java experience and 4 of Clojure,
					   he is now a big advocate of the functional approach.
					   <p>Reach me at <a href="https://twitter.com/DanLebrero">@danlebrero</a> or by <a href="mailto:dlebrero@gmail.com">email</a>.</p>
				   </div>

			      </div> <!-- /widget_text -->

	            <div class="widget widget_categories">

	               <h5 class="widget-title">Categories</h5>
	               <ul id="categories" class="link-list group"><li><a href="/tags/Architecture/index.html">Architecture (3)</a></li><li><a href="/tags/Clojure/index.html">Clojure (8)</a></li><li><a href="/tags/Java/index.html">Java (2)</a></li><li><a href="/tags/good_practices/index.html">good practices (6)</a></li><li><a href="/tags/resilience/index.html">resilience (2)</a></li><li><a href="/tags/testing/index.html">testing (5)</a></li></ul>

	            </div> <!-- /widget_categories -->

				<div class="widget">
					<h5 class="widget-title"><a href="/archives/">Archives</a></h5>
					<a href="/feed.rss"><img src="/images/feed.png" /></a>
				</div>

	             <!-- /widget_tag_cloud -->

	         </aside> <!-- /sidebar -->

	      </div> <!-- /secondary -->

	   </div> <!-- /row -->

   </section> <!-- /content -->


   <!-- Footer
   ================================================== -->
   <footer>

	   <p class="copyright">© Copyright 2016 Daniel Lebrero. Design by <a href="http://www.styleshout.com/">Styleshout.</a></p>

	   <div id="go-top">
		   <a class="smoothscroll" title="Back to Top" href="#content"><span>Top</span><i class="fa fa-long-arrow-up"></i></a>
	   </div>


   </footer> <!-- /footer -->


   <!-- Java Script
   ================================================== -->
	<div id="scripts" style="display:none;">
	   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
	   <script src="/js/jquery-1.10.2.min.js"></script>
	   <script type="text/javascript" src="/js/jquery-migrate-1.2.1.min.js"></script>
	   <script src="/js/jquery.flexslider.js"></script>
	   <script src="/js/jquery.fittext.js"></script>
	   <script src="/js/backstretch.js"></script>
	   <script src="/js/waypoints.js"></script>
	   <script src="/js/main.js"></script>
	   <script src="/js/highlight.pack.js"></script>
	   <script src="/js/shariff.min.js"></script>
	   <script>hljs.initHighlightingOnLoad();</script>
	   <script>
$(document).ready(function() {
	$(".shariff").find('a').each(function() {
		var which = $(this).attr("title").substr(9);;
		$(this).click(function(event) {
			ga('send', 'social', which, 'share', window.location.href);
		});
	});
});
		</script>
	   <div id="debug" style="display: none;">
	   </div>
   </div>


</body>

</html>